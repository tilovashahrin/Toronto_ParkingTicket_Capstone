{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d253f8c",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "## Author: Tilova Shahrin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504735c",
   "metadata": {},
   "source": [
    "Table of Contents:\n",
    "\n",
    "- [Coordinates API using Geopy](#geoapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28ce1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e380a7",
   "metadata": {},
   "source": [
    "Recall we downloaded a new csv file from our cleaning in the last file `Cleaning and EDA`. Let's upload the file into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "262afd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_df = pd.read_csv('../data/parking_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06db131b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_of_infraction</th>\n",
       "      <th>infraction_code</th>\n",
       "      <th>infraction_description</th>\n",
       "      <th>set_fine_amount</th>\n",
       "      <th>time_of_infraction</th>\n",
       "      <th>location1</th>\n",
       "      <th>location2</th>\n",
       "      <th>location3</th>\n",
       "      <th>location4</th>\n",
       "      <th>province</th>\n",
       "      <th>datetime_of_infraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>403.0</td>\n",
       "      <td>STOP-SIGNED HIGHWAY-RUSH HOUR</td>\n",
       "      <td>150</td>\n",
       "      <td>16:37:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>1546 BLOOR ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-12-30 16:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>403.0</td>\n",
       "      <td>STOP-SIGNED HIGHWAY-RUSH HOUR</td>\n",
       "      <td>150</td>\n",
       "      <td>16:37:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>5418 YONGE ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-12-30 16:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>403.0</td>\n",
       "      <td>STOP-SIGNED HIGHWAY-RUSH HOUR</td>\n",
       "      <td>150</td>\n",
       "      <td>16:37:00</td>\n",
       "      <td>OPP</td>\n",
       "      <td>777 QUEEN ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-12-30 16:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>403.0</td>\n",
       "      <td>STOP-SIGNED HIGHWAY-RUSH HOUR</td>\n",
       "      <td>150</td>\n",
       "      <td>16:37:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>747 QUEEN ST E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-12-30 16:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>403.0</td>\n",
       "      <td>STOP-SIGNED HIGHWAY-RUSH HOUR</td>\n",
       "      <td>150</td>\n",
       "      <td>16:37:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>3042 DUNDAS ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-12-30 16:37:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_of_infraction  infraction_code         infraction_description  \\\n",
       "0         2016-12-30            403.0  STOP-SIGNED HIGHWAY-RUSH HOUR   \n",
       "1         2016-12-30            403.0  STOP-SIGNED HIGHWAY-RUSH HOUR   \n",
       "2         2016-12-30            403.0  STOP-SIGNED HIGHWAY-RUSH HOUR   \n",
       "3         2016-12-30            403.0  STOP-SIGNED HIGHWAY-RUSH HOUR   \n",
       "4         2016-12-30            403.0  STOP-SIGNED HIGHWAY-RUSH HOUR   \n",
       "\n",
       "   set_fine_amount time_of_infraction location1         location2 location3  \\\n",
       "0              150           16:37:00       N/S   1546 BLOOR ST W       NaN   \n",
       "1              150           16:37:00       N/S     5418 YONGE ST       NaN   \n",
       "2              150           16:37:00       OPP    777 QUEEN ST W       NaN   \n",
       "3              150           16:37:00       N/S    747 QUEEN ST E       NaN   \n",
       "4              150           16:37:00       N/S  3042 DUNDAS ST W       NaN   \n",
       "\n",
       "  location4 province datetime_of_infraction  \n",
       "0       NaN       ON    2016-12-30 16:37:00  \n",
       "1       NaN       ON    2016-12-30 16:37:00  \n",
       "2       NaN       ON    2016-12-30 16:37:00  \n",
       "3       NaN       ON    2016-12-30 16:37:00  \n",
       "4       NaN       ON    2016-12-30 16:37:00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a3a801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13353939 entries, 0 to 13353938\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   date_of_infraction      object \n",
      " 1   infraction_code         float64\n",
      " 2   infraction_description  object \n",
      " 3   set_fine_amount         int64  \n",
      " 4   time_of_infraction      object \n",
      " 5   location1               object \n",
      " 6   location2               object \n",
      " 7   location3               object \n",
      " 8   location4               object \n",
      " 9   province                object \n",
      " 10  datetime_of_infraction  object \n",
      "dtypes: float64(1), int64(1), object(9)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "parking_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4eb0007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_of_infraction               0\n",
       "infraction_code                  2\n",
       "infraction_description           0\n",
       "set_fine_amount                  0\n",
       "time_of_infraction               0\n",
       "location1                        0\n",
       "location2                        0\n",
       "location3                 12376426\n",
       "location4                 12374286\n",
       "province                         3\n",
       "datetime_of_infraction           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474b6f9",
   "metadata": {},
   "source": [
    "<a id='geoapi'></a>\n",
    "## Geocoders  API\n",
    "\n",
    "I want to find a way to produce geospatial analysis for my machine learning models. With that, I need geo coordinates `latitude` and `longitude`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4f974",
   "metadata": {},
   "source": [
    "We're going to use this code snippet to change address to a coordinate. However, we need to run this geolocator a lot of times.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee2e39c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edward Street, Discovery District, Universityâ€”Rosedale, Old Toronto, Toronto, Golden Horseshoe, Ontario, M5B 1R7, Canada\n",
      "(43.6566007, -79.3831637)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"toronto-parking-application\")\n",
    "location = geolocator.geocode(\"Edward St Toronto ON Canada\")\n",
    "print(location.address)\n",
    "print((location.latitude, location.longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73810981",
   "metadata": {},
   "source": [
    "Recall the shape. That is a lot of rows to process, about 13 million, even after cleaning this is going to take a while. We need to find a way to reduce the amount of API calls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdd5531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13353939, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da013e7",
   "metadata": {},
   "source": [
    "Let's get the unique values of the addresses, and apply those addresses onto any duplicate addresses. Recall the addresses with the most tickets. Some have about 30 thousand tickets. To reduce, we get the unique value, add to dictionary and find a way to use that same address after getting the coordinate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1096af3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482566"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_df['location2'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76fccfd",
   "metadata": {},
   "source": [
    "About 400k unique values. That is a lot less than the number of rows. We can use these addresses and process them onto the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28021859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1546 BLOOR ST W', '5418 YONGE ST', '777 QUEEN ST W', ...,\n",
       "       '28 LAMBERTON BLVD', '30151 GLENDALE AVE', '576 FORMAN AVE'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_df['location2'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25476e",
   "metadata": {},
   "source": [
    "Let's apply the code snippet from before to get the coordinates of these unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import json\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "# Function to geocode address\n",
    "def geocode_address(address):\n",
    "    geolocator = Nominatim(user_agent=\"toronto-parking-application\")\n",
    "    location = geolocator.geocode(address, timeout=10)\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "# get the unique values of locations\n",
    "unique_addresses = parking_df['location2'].str.lower().unique()\n",
    "\n",
    "# create dict, check if json file already exists\n",
    "try:\n",
    "    with open('address_data.json', 'r') as json_file:\n",
    "        print(f'found file {json_file}')\n",
    "        address_dict = json.load(json_file)\n",
    "except FileNotFoundError:\n",
    "    print('file DNE')\n",
    "    # if the file does not exist, initialize an empty dictionary\n",
    "    address_dict = {}\n",
    "\n",
    "#set counter \n",
    "counter = 0 \n",
    "\n",
    "try:\n",
    "    # loop through addresses\n",
    "    for address in unique_addresses:\n",
    "        address += ', toronto, on, canada'\n",
    "        # check if address is not already in the dictionary\n",
    "        if address not in address_dict.keys():\n",
    "            try:\n",
    "                # add the address to the dictionary \n",
    "                address_dict[address] = geocode_address(address)\n",
    "                counter += 1\n",
    "\n",
    "                # keep a counter, if counter at 100, save dict to json and counter to 0, otherwise increase counter\n",
    "                if counter == 100:\n",
    "                    print('Processed 100 rows')\n",
    "                    # Save the dictionary to a JSON file\n",
    "                    with open('address_data.json', 'a') as json_file:\n",
    "                        json.dump(address_dict, json_file)\n",
    "\n",
    "                    # Reset the counter\n",
    "                    counter = 0\n",
    "\n",
    "                    #sleep for second \n",
    "                    time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                print(\"Saving the collected data to a JSON file.\")\n",
    "                with open('address_data.json', 'a') as json_file:\n",
    "                    json.dump(address_dict, json_file)\n",
    "                raise\n",
    "                \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Keyboard Interrupt.\")\n",
    "    print(\"Saving the collected data to a JSON file.\")\n",
    "    with open('address_data.json', 'a') as json_file:\n",
    "        json.dump(address_dict, json_file)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a7397",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5af74d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found file <_io.TextIOWrapper name='address_data.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 1 column 1069314 (char 1069313)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfound file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     address_dict \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1546 bloor st w, toronto, on, canada\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m address_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mit exists\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.8/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 1 column 1069314 (char 1069313)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "f = open('address_data.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "for i in data['emp_details']:\n",
    "    print(i)\n",
    " \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cace0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
