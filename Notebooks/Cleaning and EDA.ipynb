{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c0d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c1fca",
   "metadata": {},
   "source": [
    "### Combining 2016 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b5039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2016 = \"../data/parking-tickets-2016\"\n",
    "#list all the files from the directory\n",
    "file_list_2016 = os.listdir(file_path_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c34a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2016:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2016/{file}')\n",
    "    df_2016 = pd.concat([df_2016, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e5bb5e",
   "metadata": {},
   "source": [
    "### Combining 2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6c4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2017 = \"../data/parking-tickets-2017\"\n",
    "#list all the files from the directory\n",
    "file_list_2017 = os.listdir(file_path_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ea0044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2017 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2017:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2017/{file}')\n",
    "    df_2017 = pd.concat([df_2017, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40805e07",
   "metadata": {},
   "source": [
    "### Combining 2018 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e67459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2018 = \"../data/parking-tickets-2018\"\n",
    "#list all the files from the directory\n",
    "file_list_2018 = os.listdir(file_path_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410f509e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2018 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2018:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2018/{file}')\n",
    "    df_2018 = pd.concat([df_2018, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f34e28a",
   "metadata": {},
   "source": [
    "### Combining 2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107b8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2019 = \"../data/parking-tickets-2019\"\n",
    "#list all the files from the directory\n",
    "file_list_2019 = os.listdir(file_path_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd15608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2019:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2019/{file}')\n",
    "    df_2019 = pd.concat([df_2019, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cddc35",
   "metadata": {},
   "source": [
    "### Combining 2020 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "273b9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2020 = \"../data/parking-tickets-2020\"\n",
    "#list all the files from the directory\n",
    "file_list_2020 = os.listdir(file_path_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2380d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2020:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2020/{file}')\n",
    "    df_2020 = pd.concat([df_2020, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f775d7e",
   "metadata": {},
   "source": [
    "### Combining 2021 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7cab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2021 = \"../data/parking-tickets-2021\"\n",
    "#list all the files from the directory\n",
    "file_list_2021 = os.listdir(file_path_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40446f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2021 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2021:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2021/{file}')\n",
    "    df_2021 = pd.concat([df_2021, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5993ada",
   "metadata": {},
   "source": [
    "### Combining 2022 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723e28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2022 = \"../data/parking-tickets-2022\"\n",
    "#list all the files from the directory\n",
    "file_list_2022 = os.listdir(file_path_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a41ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2022:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2022/{file}')\n",
    "    df_2022 = pd.concat([df_2022, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e1e93",
   "metadata": {},
   "source": [
    "### Merging Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0f3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_2016, df_2017, df_2018, df_2019, df_2020, df_2021, df_2022]\n",
    "df_merged = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae01b63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13364473 entries, 0 to 1821886\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   tag_number_masked       object \n",
      " 1   date_of_infraction      int64  \n",
      " 2   infraction_code         float64\n",
      " 3   infraction_description  object \n",
      " 4   set_fine_amount         int64  \n",
      " 5   time_of_infraction      float64\n",
      " 6   location1               object \n",
      " 7   location2               object \n",
      " 8   location3               object \n",
      " 9   location4               object \n",
      " 10  province                object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0722c609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13364473, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c68c2c",
   "metadata": {},
   "source": [
    "#### Going to check what each column means, starting with `tag_number_masked`. Seems like they are the id number for each ticket made. Let's see if there are any unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50666ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100022"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['tag_number_masked'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e550ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7484170905953418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['tag_number_masked'].nunique()/df_merged.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb3bec",
   "metadata": {},
   "source": [
    "#### There's 100k unique values of almost 13 million entries. Not sure how this column can help us, or what findings I may have, but it is best to leave it alone until I find out the best use for this column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08aed2",
   "metadata": {},
   "source": [
    "#### Next is `date_of_infraction`, we can change this to a datetime64[ns] format. But I noticed another column that gives me the time, `time_of_infraction` displayed in minutes. We can change both of these into datetime by combining them together into a new column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62ed40-6e0b-4403-abe2-7ba3b7ec30a1",
   "metadata": {},
   "source": [
    "Checking for info or null values first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c0ec1f-0393-4704-a827-2d8222d7295c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['date_of_infraction'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ed149-5664-4e91-85e2-8f36c3f7e6f7",
   "metadata": {},
   "source": [
    "We have no null values for `date_of_infraction` but we do for `time_of_infraction`. So once we combine them we will get 9337 null values. Let's get the average time for each day of the year and use that value to fill in the null values. Let's move on to changing its `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16ebe39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20161230\n",
       "1    20161230\n",
       "2    20161230\n",
       "3    20161230\n",
       "4    20161230\n",
       "Name: date_of_infraction, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['date_of_infraction'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d5aa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2016-12-30\n",
       "1   2016-12-30\n",
       "2   2016-12-30\n",
       "3   2016-12-30\n",
       "4   2016-12-30\n",
       "Name: date_of_infraction, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['date_of_infraction'] = pd.to_datetime(df_merged['date_of_infraction'], format='%Y%m%d')\n",
    "df_merged['date_of_infraction'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "590f5200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1637.0\n",
       "1    1637.0\n",
       "2    1637.0\n",
       "3    1637.0\n",
       "4    1637.0\n",
       "Name: time_of_infraction, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['time_of_infraction'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ab52a",
   "metadata": {},
   "source": [
    "I cannot just change this by making unit into minutes, otherwise 1637 will give me a combination of minutes instead of separating hours and minutes into 16:37:00, \n",
    "let's do a format by breaking it down to hours and minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e1bcfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['hours'] = df_merged['time_of_infraction'] // 100\n",
    "df_merged['minutes'] = df_merged['time_of_infraction'] % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53f3558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['hours'] = pd.to_timedelta(df_merged['hours'], unit='h')\n",
    "df_merged['minutes'] = pd.to_timedelta(df_merged['minutes'], unit='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3967d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine date and time columns into a single datetime column\n",
    "df_merged['time_of_infraction'] = (df_merged['hours'] + df_merged['minutes']).astype(str)\n",
    "df_merged['time_of_infraction'] = df_merged['time_of_infraction'].astype(str).str.split().str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b7f22ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          16:37:00\n",
       "1          16:37:00\n",
       "2          16:37:00\n",
       "3          16:37:00\n",
       "4          16:37:00\n",
       "             ...   \n",
       "1821882    09:46:00\n",
       "1821883    09:47:00\n",
       "1821884    09:47:00\n",
       "1821885    09:47:00\n",
       "1821886    09:47:00\n",
       "Name: time_of_infraction, Length: 13364473, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['time_of_infraction']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8186b2",
   "metadata": {},
   "source": [
    "#### Since I have date and time, I don't think I need a necessary datetime of both, so I shall leave that separate for now, unless necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4eac8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not running, non existent\n",
    "df_merged['datetime_of_infraction'] = df_merged['date_of_infraction'] + df_merged['hours'] + df_merged['minutes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade198f",
   "metadata": {},
   "source": [
    "Now we can see this as its own column. Best to remove `hours` and `minutes` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ada019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(columns = ['hours', 'minutes'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d220b",
   "metadata": {},
   "source": [
    "As mentioned before, we'll have some null values in `time_of_infraction` we'd have to look into. 9337 time entries. Let's see if we can get average time by day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72a42f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_number_masked         2996\n",
       "date_of_infraction        2996\n",
       "infraction_code           2996\n",
       "infraction_description    2996\n",
       "set_fine_amount           2996\n",
       "time_of_infraction        2996\n",
       "location1                 2621\n",
       "location2                 2995\n",
       "location3                  248\n",
       "location4                  250\n",
       "province                  2996\n",
       "datetime_of_infraction    2996\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['time_of_infraction'].astype(str) == '00:00:00'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cfb17c",
   "metadata": {},
   "source": [
    "This gives us the NaT values that we need to fill, which is different from the '00:00:00' entries we've seen. This is good because we don't need to worry if the conversion changed null values changed to 0, they simply changed to NaT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "331a4302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_number_masked         9337\n",
       "date_of_infraction        9337\n",
       "infraction_code           9337\n",
       "infraction_description    9337\n",
       "set_fine_amount           9337\n",
       "time_of_infraction        9337\n",
       "location1                 1525\n",
       "location2                 9185\n",
       "location3                  107\n",
       "location4                  465\n",
       "province                  9337\n",
       "datetime_of_infraction       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['time_of_infraction'].str.contains('NaT') == True].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c08d7",
   "metadata": {},
   "source": [
    "Now that I know there's NaT values to look out for and not the 0 times. I can fill the NaT values with the average of each offence. \n",
    "\n",
    "Let's look into `infraction_description` and group by that with NaT values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eb44c28-d8d3-4637-a4ba-1227aef7b869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['infraction_description'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d35f34db-0ca7-4c32-a385-450b87633c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "infraction_description\n",
       "ANGLE PARK-METERED SPACE-FRONT                                 [17:55:00, 14:56:00]\n",
       "ANGLE PARK-TOO FAR FROM METER                                  [11:23:00, 10:23:00]\n",
       "ANGLE PARK-TOO FAR FROM METER                                            [11:33:00]\n",
       "FAIL ANGLE PARK/STOP AT 45 DEG    [08:59:00, 08:59:00, 21:00:00, 21:02:00, 16:01...\n",
       "FAIL PARK/STOP PAR RT HAND LTD                                           [14:43:00]\n",
       "                                                        ...                        \n",
       "STOP/STAND/PARK - NO VEND ZONE                                 [13:39:00, 20:37:00]\n",
       "STOP/STAND/PARK DESIGNATE AREA                                 [23:19:00, 08:20:00]\n",
       "STOP/STAND/PARK NOT DESIG AREA                                           [04:26:00]\n",
       "STOP/STAND/PARK VEND CONT ZONE                                           [20:06:00]\n",
       "STOP/STAND/PARK VEND NO PERMIT    [14:30:00, 15:30:00, 15:40:00, 17:07:00, 16:48...\n",
       "Name: time_of_infraction, Length: 291, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_per_infraction = df_merged.groupby('infraction_description')['time_of_infraction'].apply(lambda x: np.array(x))\n",
    "descriptions = times_per_infraction.index\n",
    "times_per_infraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59afa0a-9262-42b7-ad66-3c3868482d67",
   "metadata": {},
   "source": [
    "### Test for Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e0e62-7d78-448f-a5e7-e8db9ee291a7",
   "metadata": {},
   "source": [
    "I am not sure if I need to get the mean or median of the times based on distribution. Therefore, I need to check the time's histogram to see if it's normally distributed or skewed. The issue is, I cannot go through every infraction, they have 291 unique values. Let's see if I can do a statistical test and depending on the p-value, I can take the mean or the median of the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df337cc4-8dea-4991-9644-1dd55ea1d28a",
   "metadata": {},
   "source": [
    "Let's get mean for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b93ef4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/88/fzmg9qys41g9cpc25qvl9dwr0000gn/T/ipykernel_4915/1867060712.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_merged['time_of_infraction'] = pd.to_datetime(df_merged['time_of_infraction'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             infraction_description  time_of_infraction\n",
      "0    ANGLE PARK-METERED SPACE-FRONT 2024-03-03 16:26:00\n",
      "1     ANGLE PARK-TOO FAR FROM METER 2024-03-03 10:53:00\n",
      "2    ANGLE PARK-TOO FAR FROM METER  2024-03-03 11:33:00\n",
      "3    FAIL ANGLE PARK/STOP AT 45 DEG 2024-03-03 13:47:00\n",
      "4    FAIL PARK/STOP PAR RT HAND LTD 2024-03-03 14:43:00\n",
      "..                              ...                 ...\n",
      "286  STOP/STAND/PARK - NO VEND ZONE 2024-03-03 17:08:00\n",
      "287  STOP/STAND/PARK DESIGNATE AREA 2024-03-03 15:50:00\n",
      "288  STOP/STAND/PARK NOT DESIG AREA 2024-03-03 04:26:00\n",
      "289  STOP/STAND/PARK VEND CONT ZONE 2024-03-03 20:06:00\n",
      "290  STOP/STAND/PARK VEND NO PERMIT 2024-03-03 15:00:00\n",
      "\n",
      "[291 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_merged['time_of_infraction'] = pd.to_datetime(df_merged['time_of_infraction'])\n",
    "\n",
    "# Group by infraction_description and calculate the mean time\n",
    "average_times = df_merged.groupby('infraction_description')['time_of_infraction'].apply(lambda x: np.mean(x)).reset_index()\n",
    "\n",
    "average_times['time_of_infraction'] = average_times['time_of_infraction'].apply(lambda x: x.round('T'))\n",
    "\n",
    "print(average_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbd0de",
   "metadata": {},
   "source": [
    "Let's do a sanity check to see if there's no null values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9a1d0",
   "metadata": {},
   "source": [
    "#### Now let's apply these times to the NaT values based on the infraction description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7e27e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "1          False\n",
       "2          False\n",
       "3          False\n",
       "4          False\n",
       "           ...  \n",
       "1821882    False\n",
       "1821883    False\n",
       "1821884    False\n",
       "1821885    False\n",
       "1821886    False\n",
       "Name: time_of_infraction, Length: 13364473, dtype: bool"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nat_counts = df_merged['time_of_infraction'].isna()\n",
    "nat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4019b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#info on itterrows - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html\n",
    "\n",
    "for index, row in df_merged[nat_counts].iterrows():\n",
    "    infraction_description = row['infraction_description']\n",
    "        \n",
    "    average_time = average_times[average_times['infraction_description'] == infraction_description]['time_of_infraction'].values[0]\n",
    "    \n",
    "    df_merged.at[index, 'time_of_infraction'] = average_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "995b9b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['time_of_infraction'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fc00a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tag_number_masked date_of_infraction  infraction_code  \\\n",
      "259120           ***15741         2016-10-06             15.0   \n",
      "1743918          ***12465         2016-02-09             28.0   \n",
      "2089001          ***54675         2016-04-05              7.0   \n",
      "259120           ***51151         2017-02-11             18.0   \n",
      "1743918          ***78426         2017-06-28              5.0   \n",
      "2089001          ***21138         2017-08-25              5.0   \n",
      "259120           ***38476         2018-11-10            207.0   \n",
      "1743918          ***61354         2018-03-25            207.0   \n",
      "259120           ***66808         2019-04-08             77.0   \n",
      "1743918          ***80112         2019-10-21              5.0   \n",
      "2089001          ***09600         2019-09-27              5.0   \n",
      "259120           ***57030         2020-11-23              5.0   \n",
      "259120           ***21491         2021-02-02            134.0   \n",
      "259120           ***95569         2022-06-08              4.0   \n",
      "1743918          ***79165         2022-11-26              9.0   \n",
      "\n",
      "                 infraction_description  set_fine_amount time_of_infraction  \\\n",
      "259120   PARK-WITHIN 3M OF FIRE HYDRANT              100                NaT   \n",
      "1743918  PARK-N.YORK 2AM-6AM DEC1-MAR31               40                NaT   \n",
      "2089001               PARK - FIRE ROUTE                0                NaT   \n",
      "259120    PARK HWY 30.5 M OF SIGNAL INT                0                NaT   \n",
      "1743918  PARK SIGNED HWY PRO TIMES/DAYS                0                NaT   \n",
      "2089001  PARK-SIGNED HWY-PROHIBIT DY/TM               50                NaT   \n",
      "259120   PARK MACHINE-REQD FEE NOT PAID               30                NaT   \n",
      "1743918  PARK MACHINE-REQD FEE NOT PAID               30                NaT   \n",
      "259120   PARK-(FRNT/60 CM) DRWAY/LANEWY               50                NaT   \n",
      "1743918  PARK-SIGNED HWY-PROHIBIT DY/TM               50                NaT   \n",
      "2089001  PARK-SIGNED HWY-PROHIBIT DY/TM               50                NaT   \n",
      "259120   PARK-SIGNED HWY-PROHIBIT DY/TM               50                NaT   \n",
      "259120      PARK-SIGNED HWY-PUBLIC LANE               40                NaT   \n",
      "259120       PARK ON MUNICIPAL PROPERTY               30                NaT   \n",
      "1743918  STOP-SIGNED HWY-PROHIBIT TM/DY              100                NaT   \n",
      "\n",
      "        location1          location2 location3  location4 province  \\\n",
      "259120         AT     5465A YONGE ST       NaN    TORONTO       ON   \n",
      "1743918        NR    47 HARNWORTH DR       NaN        NaN       ON   \n",
      "2089001       NaN  89 HUMBER COLLEGE       NaN        NaN       ON   \n",
      "259120        NaN  52 ORPINGTON CRES       NaN        NaN       ON   \n",
      "1743918       NaN       8 VENDOME PL       NaN        NaN       ON   \n",
      "2089001        NR     27 ORIOLE GDNS       NaN        NaN       ON   \n",
      "259120         NR   88 YORKVILLE AVE       NaN        NaN       ON   \n",
      "1743918        NR      27 CARLTON ST       NaN        NaN       ON   \n",
      "259120         NR         4 CLIFF ST       NaN        NaN       ON   \n",
      "1743918       OPP       2 LAWLOR AVE       NaN        NaN       ON   \n",
      "2089001        NR  179 GLADSTONE AVE       NaN        NaN       ON   \n",
      "259120         NR      66 SOUDAN AVE       NaN        NaN       ON   \n",
      "259120        W/S       O'KEEFE LANE       N/O  SHUTER ST       ON   \n",
      "259120        NaN    155 TRANSWAY CR       NaN        NaN       ON   \n",
      "1743918        NR         700 BAY ST       NaN        NaN       ON   \n",
      "\n",
      "        datetime_of_infraction  \n",
      "259120     2016-10-06 02:24:00  \n",
      "1743918    2016-02-09 03:00:00  \n",
      "2089001                    NaT  \n",
      "259120                     NaT  \n",
      "1743918                    NaT  \n",
      "2089001    2017-08-25 09:16:00  \n",
      "259120     2018-11-10 12:08:00  \n",
      "1743918    2018-03-25 20:48:00  \n",
      "259120     2019-04-08 12:57:00  \n",
      "1743918    2019-10-21 13:00:00  \n",
      "2089001    2019-09-27 09:17:00  \n",
      "259120     2020-11-23 07:25:00  \n",
      "259120     2021-02-02 14:31:00  \n",
      "259120     2022-06-08 11:28:00  \n",
      "1743918    2022-11-26 08:25:00  \n"
     ]
    }
   ],
   "source": [
    "rows_with_nan = df_merged[df_merged['time_of_infraction'].isna()]\n",
    "\n",
    "# Display the rows with NaN values\n",
    "print(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b729d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
