{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c0d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c1fca",
   "metadata": {},
   "source": [
    "### Combining 2016 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b5039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2016 = \"../data/parking-tickets-2016\"\n",
    "#list all the files from the directory\n",
    "file_list_2016 = os.listdir(file_path_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c34a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2016:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2016/{file}')\n",
    "    df_2016 = pd.concat([df_2016, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e5bb5e",
   "metadata": {},
   "source": [
    "### Combining 2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6c4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2017 = \"../data/parking-tickets-2017\"\n",
    "#list all the files from the directory\n",
    "file_list_2017 = os.listdir(file_path_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ea0044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2017 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2017:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2017/{file}')\n",
    "    df_2017 = pd.concat([df_2017, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40805e07",
   "metadata": {},
   "source": [
    "### Combining 2018 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e67459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2018 = \"../data/parking-tickets-2018\"\n",
    "#list all the files from the directory\n",
    "file_list_2018 = os.listdir(file_path_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410f509e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2018 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2018:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2018/{file}')\n",
    "    df_2018 = pd.concat([df_2018, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f34e28a",
   "metadata": {},
   "source": [
    "### Combining 2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107b8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2019 = \"../data/parking-tickets-2019\"\n",
    "#list all the files from the directory\n",
    "file_list_2019 = os.listdir(file_path_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd15608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2019:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2019/{file}')\n",
    "    df_2019 = pd.concat([df_2019, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cddc35",
   "metadata": {},
   "source": [
    "### Combining 2020 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "273b9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2020 = \"../data/parking-tickets-2020\"\n",
    "#list all the files from the directory\n",
    "file_list_2020 = os.listdir(file_path_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2380d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2020:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2020/{file}')\n",
    "    df_2020 = pd.concat([df_2020, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f775d7e",
   "metadata": {},
   "source": [
    "### Combining 2021 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7cab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2021 = \"../data/parking-tickets-2021\"\n",
    "#list all the files from the directory\n",
    "file_list_2021 = os.listdir(file_path_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40446f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2021 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2021:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2021/{file}')\n",
    "    df_2021 = pd.concat([df_2021, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5993ada",
   "metadata": {},
   "source": [
    "### Combining 2022 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723e28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2022 = \"../data/parking-tickets-2022\"\n",
    "#list all the files from the directory\n",
    "file_list_2022 = os.listdir(file_path_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a41ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2022:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2022/{file}')\n",
    "    df_2022 = pd.concat([df_2022, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e1e93",
   "metadata": {},
   "source": [
    "### Merging Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0f3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_2016, df_2017, df_2018, df_2019, df_2020, df_2021, df_2022]\n",
    "df_merged = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae01b63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13364473 entries, 0 to 1821886\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   tag_number_masked       object \n",
      " 1   date_of_infraction      int64  \n",
      " 2   infraction_code         float64\n",
      " 3   infraction_description  object \n",
      " 4   set_fine_amount         int64  \n",
      " 5   time_of_infraction      float64\n",
      " 6   location1               object \n",
      " 7   location2               object \n",
      " 8   location3               object \n",
      " 9   location4               object \n",
      " 10  province                object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0722c609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13364473, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c68c2c",
   "metadata": {},
   "source": [
    "#### Going to check what each column means, starting with `tag_number_masked`. Seems like they are the id number for each ticket made. Let's see if there are any unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50666ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100022"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['tag_number_masked'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e550ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7484170905953418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['tag_number_masked'].nunique()/df_merged.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb3bec",
   "metadata": {},
   "source": [
    "#### There's 100k unique values of almost 13 million entries. Not sure how this column can help us, or what findings I may have, but it is best to leave it alone until I find out the best use for this column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08aed2",
   "metadata": {},
   "source": [
    "#### Next is `date_of_infraction`, we can change this to a datetime64[ns] format. But I noticed another column that gives me the time, `time_of_infraction` displayed in minutes. We can change both of these into datetime by combining them together into a new column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62ed40-6e0b-4403-abe2-7ba3b7ec30a1",
   "metadata": {},
   "source": [
    "Checking for info or null values first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c0ec1f-0393-4704-a827-2d8222d7295c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['date_of_infraction'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ed149-5664-4e91-85e2-8f36c3f7e6f7",
   "metadata": {},
   "source": [
    "We have no null values for `date_of_infraction` but we do for `time_of_infraction`. So once we combine them we will get 9337 null values. Let's get the average time for each day of the year and use that value to fill in the null values. Let's move on to changing its `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16ebe39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20161230\n",
       "1    20161230\n",
       "2    20161230\n",
       "3    20161230\n",
       "4    20161230\n",
       "Name: date_of_infraction, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['date_of_infraction'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d5aa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2016-12-30\n",
       "1   2016-12-30\n",
       "2   2016-12-30\n",
       "3   2016-12-30\n",
       "4   2016-12-30\n",
       "Name: date_of_infraction, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['date_of_infraction'] = pd.to_datetime(df_merged['date_of_infraction'], format='%Y%m%d')\n",
    "df_merged['date_of_infraction'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "590f5200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1637.0\n",
       "1    1637.0\n",
       "2    1637.0\n",
       "3    1637.0\n",
       "4    1637.0\n",
       "Name: time_of_infraction, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['time_of_infraction'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ab52a",
   "metadata": {},
   "source": [
    "I cannot just change this by making unit into minutes, otherwise 1637 will give me a combination of minutes instead of separating hours and minutes into 16:37:00, \n",
    "let's do a format by breaking it down to hours and minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e1bcfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['hours'] = df_merged['time_of_infraction'] // 100\n",
    "df_merged['minutes'] = df_merged['time_of_infraction'] % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53f3558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['hours'] = pd.to_timedelta(df_merged['hours'], unit='h')\n",
    "df_merged['minutes'] = pd.to_timedelta(df_merged['minutes'], unit='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine date and time columns into a single datetime column\n",
    "df_merged['time_of_infraction'] = (df_merged['hours'] + df_merged['minutes']).astype(str)\n",
    "df_merged['time_of_infraction'] = df_merged['time_of_infraction'].astype(str).str.split().str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f22ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['time_of_infraction']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8186b2",
   "metadata": {},
   "source": [
    "#### Since I have date and time, I don't think I need a necessary datetime of both, so I shall leave that separate for now, unless necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eac8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not running, non existent\n",
    "df_merged['datetime_of_infraction'] = df_merged['date_of_infraction'] + df_merged['hours'] + df_merged['minutes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade198f",
   "metadata": {},
   "source": [
    "Now we can see this as its own column. Best to remove `hours` and `minutes` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(columns = ['hours', 'minutes'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d220b",
   "metadata": {},
   "source": [
    "As mentioned before, we'll have some null values in `time_of_infraction` we'd have to look into. 9337 time entries. Let's see if we can get average time by day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a42f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['time_of_infraction'].astype(str) == '00:00:00'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cfb17c",
   "metadata": {},
   "source": [
    "This gives us the NaT values that we need to fill, which is different from the '00:00:00' entries we've seen. This is good because we don't need to worry if the conversion changed null values changed to 0, they simply changed to NaT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[df_merged['time_of_infraction'].str.contains('NaT') == True].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c08d7",
   "metadata": {},
   "source": [
    "Now that I know there's NaT values to look out for and not the 0 times. I can fill the NaT values with the average of each offence. \n",
    "\n",
    "Let's look into `infraction_description` and group by that with NaT values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb44c28-d8d3-4637-a4ba-1227aef7b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['infraction_description'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f34db-0ca7-4c32-a385-450b87633c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_per_infraction = df_merged.groupby('infraction_description')['time_of_infraction'].apply(lambda x: np.array(x))\n",
    "descriptions = times_per_infraction.index\n",
    "times_per_infraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59afa0a-9262-42b7-ad66-3c3868482d67",
   "metadata": {},
   "source": [
    "### Test for Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e0e62-7d78-448f-a5e7-e8db9ee291a7",
   "metadata": {},
   "source": [
    "I am not sure if I need to get the mean or median of the times based on distribution. Therefore, I need to check the time's histogram to see if it's normally distributed or skewed. The issue is, I cannot go through every infraction, they have 291 unique values. Let's see if I can do a statistical test and depending on the p-value, I can take the mean or the median of the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df337cc4-8dea-4991-9644-1dd55ea1d28a",
   "metadata": {},
   "source": [
    "Let's get mean for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30442bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['time_of_infraction'] = pd.to_datetime(df_merged['time_of_infraction'])\n",
    "\n",
    "# Group by infraction_description and calculate the mean time\n",
    "average_times = df_merged.groupby('infraction_description')['time_of_infraction'].apply(lambda x: np.mean(x)).reset_index()\n",
    "\n",
    "average_times['time_of_infraction'] = average_times['time_of_infraction'].apply(lambda x: x.round('T'))\n",
    "\n",
    "print(average_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1788187f",
   "metadata": {},
   "source": [
    "Let's do a sanity check to see if there's no null values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589ee2c0",
   "metadata": {},
   "source": [
    "#### Now let's apply these times to the NaT values based on the infraction description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a002e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_counts = df_merged['time_of_infraction'].isna()\n",
    "nat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#info on itterrows - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html\n",
    "\n",
    "for index, row in df_merged[nat_counts].iterrows():\n",
    "    infraction_description = row['infraction_description']\n",
    "        \n",
    "    average_time = average_times[average_times['infraction_description'] == infraction_description]['time_of_infraction'].values[0]\n",
    "    \n",
    "    df_merged.at[index, 'time_of_infraction'] = average_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e605690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['time_of_infraction'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b60ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_nan = df_merged[df_merged['time_of_infraction'].isna()]\n",
    "\n",
    "# Display the rows with NaN values\n",
    "print(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2e643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
