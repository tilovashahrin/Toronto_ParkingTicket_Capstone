{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58c0d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202c1fca",
   "metadata": {},
   "source": [
    "### Combining 2016 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b5039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2016 = \"../data/parking-tickets-2016\"\n",
    "#list all the files from the directory\n",
    "file_list_2016 = os.listdir(file_path_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c34a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2016:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2016/{file}')\n",
    "    df_2016 = pd.concat([df_2016, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e5bb5e",
   "metadata": {},
   "source": [
    "### Combining 2017 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6c4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2017 = \"../data/parking-tickets-2017\"\n",
    "#list all the files from the directory\n",
    "file_list_2017 = os.listdir(file_path_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ea0044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2017 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2017:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2017/{file}')\n",
    "    df_2017 = pd.concat([df_2017, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40805e07",
   "metadata": {},
   "source": [
    "### Combining 2018 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e67459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2018 = \"../data/parking-tickets-2018\"\n",
    "#list all the files from the directory\n",
    "file_list_2018 = os.listdir(file_path_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410f509e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2018 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2018:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2018/{file}')\n",
    "    df_2018 = pd.concat([df_2018, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f34e28a",
   "metadata": {},
   "source": [
    "### Combining 2019 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107b8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2019 = \"../data/parking-tickets-2019\"\n",
    "#list all the files from the directory\n",
    "file_list_2019 = os.listdir(file_path_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd15608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2019:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2019/{file}')\n",
    "    df_2019 = pd.concat([df_2019, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cddc35",
   "metadata": {},
   "source": [
    "### Combining 2020 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "273b9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2020 = \"../data/parking-tickets-2020\"\n",
    "#list all the files from the directory\n",
    "file_list_2020 = os.listdir(file_path_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2380d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2020:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2020/{file}')\n",
    "    df_2020 = pd.concat([df_2020, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f775d7e",
   "metadata": {},
   "source": [
    "### Combining 2021 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7cab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2021 = \"../data/parking-tickets-2021\"\n",
    "#list all the files from the directory\n",
    "file_list_2021 = os.listdir(file_path_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40446f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2021 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2021:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2021/{file}')\n",
    "    df_2021 = pd.concat([df_2021, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5993ada",
   "metadata": {},
   "source": [
    "### Combining 2022 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723e28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the path\n",
    "file_path_2022 = \"../data/parking-tickets-2022\"\n",
    "#list all the files from the directory\n",
    "file_list_2022 = os.listdir(file_path_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a41ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2022 = pd.DataFrame()\n",
    "\n",
    "# Append all files together\n",
    "for file in file_list_2022:\n",
    "    df_temp = pd.read_csv(f'../data/parking-tickets-2022/{file}')\n",
    "    df_2022 = pd.concat([df_2022, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4e1e93",
   "metadata": {},
   "source": [
    "### Merging Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0f3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_2016, df_2017, df_2018, df_2019, df_2020, df_2021, df_2022]\n",
    "df_merged = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae01b63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13364473 entries, 0 to 1821886\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   tag_number_masked       object \n",
      " 1   date_of_infraction      int64  \n",
      " 2   infraction_code         float64\n",
      " 3   infraction_description  object \n",
      " 4   set_fine_amount         int64  \n",
      " 5   time_of_infraction      float64\n",
      " 6   location1               object \n",
      " 7   location2               object \n",
      " 8   location3               object \n",
      " 9   location4               object \n",
      " 10  province                object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 1.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0722c609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13364473, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c68c2c",
   "metadata": {},
   "source": [
    "#### Going to check what each column means, starting with `tag_number_masked`. Seems like they are the id number for each ticket made. Let's see if there are any unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50666ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100022"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['tag_number_masked'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e550ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7484170905953418"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['tag_number_masked'].nunique()/df_merged.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb3bec",
   "metadata": {},
   "source": [
    "#### There's 100k unique values of almost 13 million entries. Not sure how this column can help us, or what findings I may have, but it is best to leave it alone until I find out the best use for this column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08aed2",
   "metadata": {},
   "source": [
    "#### Next is `date_of_infraction`, we can change this to a datetime64[ns] format. But I noticed another column that gives me the time, `time_of_infraction` displayed in minutes. We can change both of these into datetime by combining them together into a new column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62ed40-6e0b-4403-abe2-7ba3b7ec30a1",
   "metadata": {},
   "source": [
    "Checking for info or null values first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c0ec1f-0393-4704-a827-2d8222d7295c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['date_of_infraction'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ed149-5664-4e91-85e2-8f36c3f7e6f7",
   "metadata": {},
   "source": [
    "We have no null values for `date_of_infraction` but we do for `time_of_infraction`. So once we combine them we will get 9337 null values. Let's get the average time for each day of the year and use that value to fill in the null values. Let's move on to changing its `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16ebe39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20161230\n",
       "1    20161230\n",
       "2    20161230\n",
       "3    20161230\n",
       "4    20161230\n",
       "Name: date_of_infraction, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['date_of_infraction'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d5aa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2016-12-30\n",
       "1   2016-12-30\n",
       "2   2016-12-30\n",
       "3   2016-12-30\n",
       "4   2016-12-30\n",
       "Name: date_of_infraction, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['date_of_infraction'] = pd.to_datetime(df_merged['date_of_infraction'], format='%Y%m%d')\n",
    "df_merged['date_of_infraction'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "590f5200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1637.0\n",
       "1    1637.0\n",
       "2    1637.0\n",
       "3    1637.0\n",
       "4    1637.0\n",
       "Name: time_of_infraction, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['time_of_infraction'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ab52a",
   "metadata": {},
   "source": [
    "I cannot just change this by making unit into minutes, otherwise 1637 will give me a combination of minutes instead of separating hours and minutes into 16:37:00, \n",
    "let's do a format by breaking it down to hours and minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e1bcfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['hours'] = df_merged['time_of_infraction'] // 100\n",
    "df_merged['minutes'] = df_merged['time_of_infraction'] % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53f3558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['hours'] = pd.to_timedelta(df_merged['hours'], unit='h')\n",
    "df_merged['minutes'] = pd.to_timedelta(df_merged['minutes'], unit='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3967d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine date and time columns into a single datetime column\n",
    "df_merged['time_of_infraction'] = (df_merged['hours'] + df_merged['minutes']).astype(str)\n",
    "df_merged['time_of_infraction'] = df_merged['time_of_infraction'].astype(str).str.split().str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b7f22ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          16:37:00\n",
       "1          16:37:00\n",
       "2          16:37:00\n",
       "3          16:37:00\n",
       "4          16:37:00\n",
       "             ...   \n",
       "1821882    09:46:00\n",
       "1821883    09:47:00\n",
       "1821884    09:47:00\n",
       "1821885    09:47:00\n",
       "1821886    09:47:00\n",
       "Name: time_of_infraction, Length: 13364473, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['time_of_infraction']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8186b2",
   "metadata": {},
   "source": [
    "#### Since I have date and time, I don't think I need a necessary datetime of both, so I shall leave that separate for now, unless necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4eac8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not running, non existent\n",
    "df_merged['datetime_of_infraction'] = df_merged['date_of_infraction'] + df_merged['hours'] + df_merged['minutes']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade198f",
   "metadata": {},
   "source": [
    "Now we can see this as its own column. Best to remove `hours` and `minutes` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ada019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(columns = ['hours', 'minutes'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d220b",
   "metadata": {},
   "source": [
    "As mentioned before, we'll have some null values in `time_of_infraction` we'd have to look into. 9337 time entries. Let's see if we can get average time by day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72a42f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_number_masked         2996\n",
       "date_of_infraction        2996\n",
       "infraction_code           2996\n",
       "infraction_description    2996\n",
       "set_fine_amount           2996\n",
       "time_of_infraction        2996\n",
       "location1                 2621\n",
       "location2                 2995\n",
       "location3                  248\n",
       "location4                  250\n",
       "province                  2996\n",
       "datetime_of_infraction    2996\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['time_of_infraction'].astype(str) == '00:00:00'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cfb17c",
   "metadata": {},
   "source": [
    "This gives us the NaT values that we need to fill, which is different from the '00:00:00' entries we've seen. This is good because we don't need to worry if the conversion changed null values changed to 0, they simply changed to NaT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "331a4302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_number_masked         9337\n",
       "date_of_infraction        9337\n",
       "infraction_code           9337\n",
       "infraction_description    9337\n",
       "set_fine_amount           9337\n",
       "time_of_infraction        9337\n",
       "location1                 1525\n",
       "location2                 9185\n",
       "location3                  107\n",
       "location4                  465\n",
       "province                  9337\n",
       "datetime_of_infraction       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['time_of_infraction'].str.contains('NaT') == True].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c08d7",
   "metadata": {},
   "source": [
    "Now that I know there's NaT values to look out for and not the 0 times. I can fill the NaT values with the average of each offence. \n",
    "\n",
    "Let's look into `infraction_description` and group by that with NaT values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eb44c28-d8d3-4637-a4ba-1227aef7b869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['infraction_description'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d35f34db-0ca7-4c32-a385-450b87633c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "infraction_description\n",
       "ANGLE PARK-METERED SPACE-FRONT                                 [17:55:00, 14:56:00]\n",
       "ANGLE PARK-TOO FAR FROM METER                                  [11:23:00, 10:23:00]\n",
       "ANGLE PARK-TOO FAR FROM METER                                            [11:33:00]\n",
       "FAIL ANGLE PARK/STOP AT 45 DEG    [08:59:00, 08:59:00, 21:00:00, 21:02:00, 16:01...\n",
       "FAIL PARK/STOP PAR RT HAND LTD                                           [14:43:00]\n",
       "                                                        ...                        \n",
       "STOP/STAND/PARK - NO VEND ZONE                                 [13:39:00, 20:37:00]\n",
       "STOP/STAND/PARK DESIGNATE AREA                                 [23:19:00, 08:20:00]\n",
       "STOP/STAND/PARK NOT DESIG AREA                                           [04:26:00]\n",
       "STOP/STAND/PARK VEND CONT ZONE                                           [20:06:00]\n",
       "STOP/STAND/PARK VEND NO PERMIT    [14:30:00, 15:30:00, 15:40:00, 17:07:00, 16:48...\n",
       "Name: time_of_infraction, Length: 291, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_per_infraction = df_merged.groupby('infraction_description')['time_of_infraction'].apply(lambda x: np.array(x))\n",
    "descriptions = times_per_infraction.index\n",
    "times_per_infraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59afa0a-9262-42b7-ad66-3c3868482d67",
   "metadata": {},
   "source": [
    "### Test for Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734e0e62-7d78-448f-a5e7-e8db9ee291a7",
   "metadata": {},
   "source": [
    "I am not sure if I need to get the mean or median of the times based on distribution. Therefore, I need to check the time's histogram to see if it's normally distributed or skewed. The issue is, I cannot go through every infraction, they have 291 unique values. Let's see if I can do a statistical test and depending on the p-value, I can take the mean or the median of the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df337cc4-8dea-4991-9644-1dd55ea1d28a",
   "metadata": {},
   "source": [
    "Let's get mean for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb98ff8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/88/fzmg9qys41g9cpc25qvl9dwr0000gn/T/ipykernel_37310/1867060712.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_merged['time_of_infraction'] = pd.to_datetime(df_merged['time_of_infraction'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             infraction_description  time_of_infraction\n",
      "0    ANGLE PARK-METERED SPACE-FRONT 2024-03-06 16:26:00\n",
      "1     ANGLE PARK-TOO FAR FROM METER 2024-03-06 10:53:00\n",
      "2    ANGLE PARK-TOO FAR FROM METER  2024-03-06 11:33:00\n",
      "3    FAIL ANGLE PARK/STOP AT 45 DEG 2024-03-06 13:47:00\n",
      "4    FAIL PARK/STOP PAR RT HAND LTD 2024-03-06 14:43:00\n",
      "..                              ...                 ...\n",
      "286  STOP/STAND/PARK - NO VEND ZONE 2024-03-06 17:08:00\n",
      "287  STOP/STAND/PARK DESIGNATE AREA 2024-03-06 15:50:00\n",
      "288  STOP/STAND/PARK NOT DESIG AREA 2024-03-06 04:26:00\n",
      "289  STOP/STAND/PARK VEND CONT ZONE 2024-03-06 20:06:00\n",
      "290  STOP/STAND/PARK VEND NO PERMIT 2024-03-06 15:00:00\n",
      "\n",
      "[291 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_merged['time_of_infraction'] = pd.to_datetime(df_merged['time_of_infraction'])\n",
    "\n",
    "# Group by infraction_description and calculate the mean time\n",
    "average_times = df_merged.groupby('infraction_description')['time_of_infraction'].apply(lambda x: np.mean(x)).reset_index()\n",
    "\n",
    "average_times['time_of_infraction'] = average_times['time_of_infraction'].apply(lambda x: x.round('T'))\n",
    "\n",
    "print(average_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d78a6",
   "metadata": {},
   "source": [
    "#### Now let's apply these times to the NaT values based on the infraction description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f16b033b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "1          False\n",
       "2          False\n",
       "3          False\n",
       "4          False\n",
       "           ...  \n",
       "1821882    False\n",
       "1821883    False\n",
       "1821884    False\n",
       "1821885    False\n",
       "1821886    False\n",
       "Name: time_of_infraction, Length: 13364473, dtype: bool"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nat_counts = df_merged['time_of_infraction'].isna()\n",
    "nat_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea68f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#info on itterrows - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html\n",
    "\n",
    "for index, row in df_merged[nat_counts].iterrows():\n",
    "    infraction_description = row['infraction_description']\n",
    "        \n",
    "    average_time = average_times[average_times['infraction_description'] == infraction_description]['time_of_infraction'].values[0]\n",
    "    \n",
    "    df_merged.at[index, 'time_of_infraction'] = average_time\n",
    "    df_merged.at[index, 'datetime_of_infraction'] = average_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07519755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 13364473 entries, 0 to 1821886\n",
      "Series name: time_of_infraction\n",
      "Non-Null Count     Dtype         \n",
      "--------------     -----         \n",
      "13364458 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 268.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_merged['time_of_infraction'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "122cb804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 13364473 entries, 0 to 1821886\n",
      "Series name: datetime_of_infraction\n",
      "Non-Null Count     Dtype         \n",
      "--------------     -----         \n",
      "13364458 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 268.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_merged['datetime_of_infraction'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bacd0631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_number_masked                0\n",
       "date_of_infraction               0\n",
       "infraction_code                  2\n",
       "infraction_description           0\n",
       "set_fine_amount                  0\n",
       "time_of_infraction              15\n",
       "location1                  1392113\n",
       "location2                     1349\n",
       "location3                 12386850\n",
       "location4                 12384345\n",
       "province                         3\n",
       "datetime_of_infraction          15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6e549",
   "metadata": {},
   "source": [
    "Let's fill na values, we know they're empty because it didn't need specification. To fill using one of the top value counts, let's fill with 'AT'. That way it is specified that it's address specified and there's no na values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "efaf3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['location1'].fillna('AT', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "843eca41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_number_masked                0\n",
       "date_of_infraction               0\n",
       "infraction_code                  2\n",
       "infraction_description           0\n",
       "set_fine_amount                  0\n",
       "time_of_infraction              15\n",
       "location1                        0\n",
       "location2                     1349\n",
       "location3                 12386850\n",
       "location4                 12384345\n",
       "province                         3\n",
       "datetime_of_infraction          15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ab2994a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location1\n",
       "NR          7409157\n",
       "AT          3203305\n",
       "OPP         1701073\n",
       "E/S          253686\n",
       "S/S          242613\n",
       "N/S          234823\n",
       "W/S          229310\n",
       "R/O           63650\n",
       "N/O            5291\n",
       "S/O            4457\n",
       "E/O            4173\n",
       "NEAR           2862\n",
       "W/O            2636\n",
       "REAR            827\n",
       "O/F             825\n",
       "N/R             569\n",
       "REAR OF         317\n",
       "ON              290\n",
       "OPPOSITE        204\n",
       "NS OF           136\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['location1'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5613e",
   "metadata": {},
   "source": [
    "Let's combine rear and rear of by replacing anything that starts with rear using regex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3803d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_number_masked</th>\n",
       "      <th>date_of_infraction</th>\n",
       "      <th>infraction_code</th>\n",
       "      <th>infraction_description</th>\n",
       "      <th>set_fine_amount</th>\n",
       "      <th>time_of_infraction</th>\n",
       "      <th>location1</th>\n",
       "      <th>location2</th>\n",
       "      <th>location3</th>\n",
       "      <th>location4</th>\n",
       "      <th>province</th>\n",
       "      <th>datetime_of_infraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123246</th>\n",
       "      <td>***25497</td>\n",
       "      <td>2016-09-14</td>\n",
       "      <td>312.0</td>\n",
       "      <td>PARKING MACH-NOT USED/NO FEE</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 17:48:00</td>\n",
       "      <td>REAR OF</td>\n",
       "      <td>5124 DUNDAS ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-14 17:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130982</th>\n",
       "      <td>***40564</td>\n",
       "      <td>2016-09-15</td>\n",
       "      <td>347.0</td>\n",
       "      <td>PARK IN A FIRE ROUTE</td>\n",
       "      <td>250</td>\n",
       "      <td>2024-03-06 22:45:00</td>\n",
       "      <td>REAR OF</td>\n",
       "      <td>128 WILLOW AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-15 22:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205348</th>\n",
       "      <td>***25901</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>312.0</td>\n",
       "      <td>PARKING MACH-NOT USED/NO FEE</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 19:21:00</td>\n",
       "      <td>REAR OF</td>\n",
       "      <td>2990 LAKE SHORE BLVD WEST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-27 19:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212956</th>\n",
       "      <td>***25904</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>312.0</td>\n",
       "      <td>PARKING MACH-NOT USED/NO FEE</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 19:33:00</td>\n",
       "      <td>REAR OF</td>\n",
       "      <td>5124 DUNDAS ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-28 19:33:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212969</th>\n",
       "      <td>***25905</td>\n",
       "      <td>2016-09-28</td>\n",
       "      <td>312.0</td>\n",
       "      <td>PARKING MACH-NOT USED/NO FEE</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 19:36:00</td>\n",
       "      <td>REAR OF</td>\n",
       "      <td>5124 DUNDAS ST W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-28 19:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720918</th>\n",
       "      <td>***09797</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 13:34:00</td>\n",
       "      <td>REAR OF</td>\n",
       "      <td>400 MCCOWAN RD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2021-11-27 13:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720931</th>\n",
       "      <td>***09798</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 13:39:00</td>\n",
       "      <td>REAR OF</td>\n",
       "      <td>400 MCCOWAN RD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2021-11-27 13:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720953</th>\n",
       "      <td>***09799</td>\n",
       "      <td>2021-11-27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 13:44:00</td>\n",
       "      <td>REAR OF</td>\n",
       "      <td>400 MCCOWAN ROAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2021-11-27 13:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918993</th>\n",
       "      <td>***59206</td>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>347.0</td>\n",
       "      <td>PARK IN A FIRE ROUTE</td>\n",
       "      <td>250</td>\n",
       "      <td>2024-03-06 19:30:00</td>\n",
       "      <td>REAR OF</td>\n",
       "      <td>3400 EGLINTON AVE E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2021-05-24 19:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242674</th>\n",
       "      <td>***42394</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>134.0</td>\n",
       "      <td>PARK-SIGNED HWY-PUBLIC LANE</td>\n",
       "      <td>40</td>\n",
       "      <td>2024-03-06 17:45:00</td>\n",
       "      <td>REAR/OF</td>\n",
       "      <td>2599 KEELE ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2021-04-24 17:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag_number_masked date_of_infraction  infraction_code  \\\n",
       "123246           ***25497         2016-09-14            312.0   \n",
       "130982           ***40564         2016-09-15            347.0   \n",
       "205348           ***25901         2016-09-27            312.0   \n",
       "212956           ***25904         2016-09-28            312.0   \n",
       "212969           ***25905         2016-09-28            312.0   \n",
       "...                   ...                ...              ...   \n",
       "720918           ***09797         2021-11-27              3.0   \n",
       "720931           ***09798         2021-11-27              3.0   \n",
       "720953           ***09799         2021-11-27              3.0   \n",
       "918993           ***59206         2021-05-24            347.0   \n",
       "1242674          ***42394         2021-04-24            134.0   \n",
       "\n",
       "                 infraction_description  set_fine_amount  time_of_infraction  \\\n",
       "123246   PARKING MACH-NOT USED/NO FEE                 30 2024-03-06 17:48:00   \n",
       "130982             PARK IN A FIRE ROUTE              250 2024-03-06 22:45:00   \n",
       "205348   PARKING MACH-NOT USED/NO FEE                 30 2024-03-06 19:21:00   \n",
       "212956   PARKING MACH-NOT USED/NO FEE                 30 2024-03-06 19:33:00   \n",
       "212969   PARKING MACH-NOT USED/NO FEE                 30 2024-03-06 19:36:00   \n",
       "...                                 ...              ...                 ...   \n",
       "720918         PARK ON PRIVATE PROPERTY               30 2024-03-06 13:34:00   \n",
       "720931         PARK ON PRIVATE PROPERTY               30 2024-03-06 13:39:00   \n",
       "720953         PARK ON PRIVATE PROPERTY               30 2024-03-06 13:44:00   \n",
       "918993             PARK IN A FIRE ROUTE              250 2024-03-06 19:30:00   \n",
       "1242674     PARK-SIGNED HWY-PUBLIC LANE               40 2024-03-06 17:45:00   \n",
       "\n",
       "        location1                  location2 location3 location4 province  \\\n",
       "123246    REAR OF           5124 DUNDAS ST W       NaN       NaN       ON   \n",
       "130982    REAR OF             128 WILLOW AVE       NaN       NaN       ON   \n",
       "205348    REAR OF  2990 LAKE SHORE BLVD WEST       NaN       NaN       ON   \n",
       "212956    REAR OF           5124 DUNDAS ST W       NaN       NaN       ON   \n",
       "212969    REAR OF           5124 DUNDAS ST W       NaN       NaN       ON   \n",
       "...           ...                        ...       ...       ...      ...   \n",
       "720918    REAR OF             400 MCCOWAN RD       NaN       NaN       ON   \n",
       "720931    REAR OF             400 MCCOWAN RD       NaN       NaN       ON   \n",
       "720953    REAR OF           400 MCCOWAN ROAD       NaN       NaN       ON   \n",
       "918993    REAR OF        3400 EGLINTON AVE E       NaN       NaN       ON   \n",
       "1242674   REAR/OF              2599 KEELE ST       NaN       NaN       ON   \n",
       "\n",
       "        datetime_of_infraction  \n",
       "123246     2016-09-14 17:48:00  \n",
       "130982     2016-09-15 22:45:00  \n",
       "205348     2016-09-27 19:21:00  \n",
       "212956     2016-09-28 19:33:00  \n",
       "212969     2016-09-28 19:36:00  \n",
       "...                        ...  \n",
       "720918     2021-11-27 13:34:00  \n",
       "720931     2021-11-27 13:39:00  \n",
       "720953     2021-11-27 13:44:00  \n",
       "918993     2021-05-24 19:30:00  \n",
       "1242674    2021-04-24 17:45:00  \n",
       "\n",
       "[343 rows x 12 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.loc[df_merged.iloc[:,6].str.contains(r'^REAR.+$', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f92aaa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^REAR.+$', 'REAR', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "974240e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location1\n",
       "NR          7409157\n",
       "AT          3203305\n",
       "OPP         1701073\n",
       "E/S          253686\n",
       "S/S          242613\n",
       "N/S          234823\n",
       "W/S          229310\n",
       "R/O           63650\n",
       "N/O            5291\n",
       "S/O            4457\n",
       "E/O            4173\n",
       "NEAR           2862\n",
       "W/O            2636\n",
       "REAR           1170\n",
       "O/F             825\n",
       "N/R             569\n",
       "ON              290\n",
       "OPPOSITE        204\n",
       "NS OF           136\n",
       "RR              111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['location1'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1d55c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^OPP.+$', 'OPP', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^NS.+$', 'N/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^E/?S.*$', 'E/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^REAR*+$', 'R/O', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^WS.+$', 'W/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^ON$', 'AT', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^N.?$', 'N/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^N.+\\sOF$', 'N/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^WS$', 'W/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^OP$', 'OPP', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^N/B$', 'N/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^E/B$', 'E/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^W/B$', 'W/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^S/?S.*$', 'S/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^N/R$', 'NEAR', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^.*AT.*$', 'AT', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^NEAR$', 'AT', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^ACROSS$', 'OPP', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^NEAR.?E/?B$', 'E/B', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^`$', 'AT', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^O(UT)? F(RONT)?$', 'AT', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^E/B$', 'E/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^S/B$', 'S/S', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^NR.+$', 'AT', regex=True)\n",
    "\n",
    "df_merged['location1'] = df_merged['location1'].str.replace(r'^.+W/B$', 'W/S', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f3277411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location1\n",
       "N/S           7644563\n",
       "AT            3207540\n",
       "OPP           1701482\n",
       "E/S            254011\n",
       "S/S            242814\n",
       "W/S            229459\n",
       "R/O             64820\n",
       "N/O              5291\n",
       "S/O              4457\n",
       "E/O              4173\n",
       "W/O              2636\n",
       "O/F               825\n",
       "RR                111\n",
       "I/F                75\n",
       "2075               39\n",
       "1                  33\n",
       "BR                 32\n",
       "UGTNTPRK           31\n",
       "18                 30\n",
       "4001               24\n",
       "T                  24\n",
       "AR                 23\n",
       "2                  22\n",
       "20                 20\n",
       "1000               19\n",
       "10                 18\n",
       "9                  17\n",
       "P1 VST PKG         17\n",
       "4700               16\n",
       "30                 16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['location1'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7e7e8deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_number_masked</th>\n",
       "      <th>date_of_infraction</th>\n",
       "      <th>infraction_code</th>\n",
       "      <th>infraction_description</th>\n",
       "      <th>set_fine_amount</th>\n",
       "      <th>time_of_infraction</th>\n",
       "      <th>location1</th>\n",
       "      <th>location2</th>\n",
       "      <th>location3</th>\n",
       "      <th>location4</th>\n",
       "      <th>province</th>\n",
       "      <th>datetime_of_infraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156747</th>\n",
       "      <td>***46255</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 09:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1340 DANFORTH RD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PQ</td>\n",
       "      <td>2016-09-20 09:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183898</th>\n",
       "      <td>***67264</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 00:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>120 TWENTY FORTH ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-07-05 00:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258451</th>\n",
       "      <td>***45837</td>\n",
       "      <td>2016-07-17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 00:27:00</td>\n",
       "      <td>7</td>\n",
       "      <td>CRESCENT PL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-07-17 00:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313015</th>\n",
       "      <td>***26912</td>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 23:26:00</td>\n",
       "      <td>1</td>\n",
       "      <td>30 GILDER DR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-07-25 23:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394295</th>\n",
       "      <td>***35616</td>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PARK ON MUNICIPAL PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 14:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>18 HENDON AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-08-08 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125493</th>\n",
       "      <td>***08993</td>\n",
       "      <td>2022-08-15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 02:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0 MEADOWGLEN PL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-08-15 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307188</th>\n",
       "      <td>***09020</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 02:05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0 MEADOWGLEN PL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-09-19 02:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463749</th>\n",
       "      <td>***36215</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 09:20:00</td>\n",
       "      <td>9</td>\n",
       "      <td>BOGERT AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-10-18 09:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572442</th>\n",
       "      <td>***15995</td>\n",
       "      <td>2022-10-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 20:17:00</td>\n",
       "      <td>5</td>\n",
       "      <td>BELLEVUE GROVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-10-24 20:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667205</th>\n",
       "      <td>***03980</td>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 00:58:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0 FALSTAFF AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-11-11 00:58:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag_number_masked date_of_infraction  infraction_code  \\\n",
       "156747           ***46255         2016-09-20              3.0   \n",
       "1183898          ***67264         2016-07-05              3.0   \n",
       "1258451          ***45837         2016-07-17              3.0   \n",
       "1313015          ***26912         2016-07-25              3.0   \n",
       "1394295          ***35616         2016-08-08              4.0   \n",
       "...                   ...                ...              ...   \n",
       "1125493          ***08993         2022-08-15              3.0   \n",
       "1307188          ***09020         2022-09-19              3.0   \n",
       "1463749          ***36215         2022-10-18              3.0   \n",
       "1572442          ***15995         2022-10-24              3.0   \n",
       "1667205          ***03980         2022-11-11              3.0   \n",
       "\n",
       "             infraction_description  set_fine_amount  time_of_infraction  \\\n",
       "156747     PARK ON PRIVATE PROPERTY               30 2024-03-06 09:50:00   \n",
       "1183898    PARK ON PRIVATE PROPERTY               30 2024-03-06 00:50:00   \n",
       "1258451    PARK ON PRIVATE PROPERTY               30 2024-03-06 00:27:00   \n",
       "1313015    PARK ON PRIVATE PROPERTY               30 2024-03-06 23:26:00   \n",
       "1394295  PARK ON MUNICIPAL PROPERTY               30 2024-03-06 14:00:00   \n",
       "...                             ...              ...                 ...   \n",
       "1125493    PARK ON PRIVATE PROPERTY               30 2024-03-06 02:00:00   \n",
       "1307188    PARK ON PRIVATE PROPERTY               30 2024-03-06 02:05:00   \n",
       "1463749    PARK ON PRIVATE PROPERTY               30 2024-03-06 09:20:00   \n",
       "1572442    PARK ON PRIVATE PROPERTY               30 2024-03-06 20:17:00   \n",
       "1667205    PARK ON PRIVATE PROPERTY               30 2024-03-06 00:58:00   \n",
       "\n",
       "        location1            location2 location3 location4 province  \\\n",
       "156747          1     1340 DANFORTH RD       NaN       NaN       PQ   \n",
       "1183898         1  120 TWENTY FORTH ST       NaN       NaN       ON   \n",
       "1258451         7          CRESCENT PL       NaN       NaN       ON   \n",
       "1313015         1         30 GILDER DR       NaN       NaN       ON   \n",
       "1394295         1        18 HENDON AVE       NaN       NaN       ON   \n",
       "...           ...                  ...       ...       ...      ...   \n",
       "1125493         3      0 MEADOWGLEN PL       NaN       NaN       ON   \n",
       "1307188         3      0 MEADOWGLEN PL       NaN       NaN       ON   \n",
       "1463749         9        BOGERT AVENUE       NaN       NaN       ON   \n",
       "1572442         5       BELLEVUE GROVE       NaN       NaN       ON   \n",
       "1667205         2       0 FALSTAFF AVE       NaN       NaN       ON   \n",
       "\n",
       "        datetime_of_infraction  \n",
       "156747     2016-09-20 09:50:00  \n",
       "1183898    2016-07-05 00:50:00  \n",
       "1258451    2016-07-17 00:27:00  \n",
       "1313015    2016-07-25 23:26:00  \n",
       "1394295    2016-08-08 14:00:00  \n",
       "...                        ...  \n",
       "1125493    2022-08-15 02:00:00  \n",
       "1307188    2022-09-19 02:05:00  \n",
       "1463749    2022-10-18 09:20:00  \n",
       "1572442    2022-10-24 20:17:00  \n",
       "1667205    2022-11-11 00:58:00  \n",
       "\n",
       "[122 rows x 12 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove 0 from location 2 and merge any numbers from location 1 onto location 2 \n",
    "#and set the value for location 1 to AT\n",
    "\n",
    "df_merged[df_merged['location1'].str.contains(r'^[0-9]$', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1d13952a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_number_masked</th>\n",
       "      <th>date_of_infraction</th>\n",
       "      <th>infraction_code</th>\n",
       "      <th>infraction_description</th>\n",
       "      <th>set_fine_amount</th>\n",
       "      <th>time_of_infraction</th>\n",
       "      <th>location1</th>\n",
       "      <th>location2</th>\n",
       "      <th>location3</th>\n",
       "      <th>location4</th>\n",
       "      <th>province</th>\n",
       "      <th>datetime_of_infraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13667</th>\n",
       "      <td>***96306</td>\n",
       "      <td>2016-08-28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 05:56:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-08-28 05:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39798</th>\n",
       "      <td>***60451</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 09:59:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-01 09:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46252</th>\n",
       "      <td>***41094</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 03:42:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-02 03:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52533</th>\n",
       "      <td>***77827</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>PARK-SIGNED HWY-EXC PERMT TIME</td>\n",
       "      <td>40</td>\n",
       "      <td>2024-03-06 23:29:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-02 23:29:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52598</th>\n",
       "      <td>***35429</td>\n",
       "      <td>2016-09-02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 09:46:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2024-03-06 09:46:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681044</th>\n",
       "      <td>***04323</td>\n",
       "      <td>2022-11-14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 00:05:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-11-14 00:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707684</th>\n",
       "      <td>***21426</td>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>347.0</td>\n",
       "      <td>PARK IN A FIRE ROUTE</td>\n",
       "      <td>250</td>\n",
       "      <td>2024-03-06 14:23:00</td>\n",
       "      <td>FIRE ROUTE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2024-03-06 14:23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765660</th>\n",
       "      <td>***04293</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 01:57:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-12-01 01:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780322</th>\n",
       "      <td>***32978</td>\n",
       "      <td>2022-12-03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>STAND VEH.-PROHIBIT TIME/DAY</td>\n",
       "      <td>100</td>\n",
       "      <td>2024-03-06 18:43:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-12-03 18:43:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791573</th>\n",
       "      <td>***94531</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 07:45:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-12-06 07:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1349 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag_number_masked date_of_infraction  infraction_code  \\\n",
       "13667            ***96306         2016-08-28              3.0   \n",
       "39798            ***60451         2016-09-01              3.0   \n",
       "46252            ***41094         2016-09-02              3.0   \n",
       "52533            ***77827         2016-09-02              6.0   \n",
       "52598            ***35429         2016-09-02              3.0   \n",
       "...                   ...                ...              ...   \n",
       "1681044          ***04323         2022-11-14              3.0   \n",
       "1707684          ***21426         2022-11-18            347.0   \n",
       "1765660          ***04293         2022-12-01              3.0   \n",
       "1780322          ***32978         2022-12-03              8.0   \n",
       "1791573          ***94531         2022-12-06              3.0   \n",
       "\n",
       "                 infraction_description  set_fine_amount  time_of_infraction  \\\n",
       "13667          PARK ON PRIVATE PROPERTY               30 2024-03-06 05:56:00   \n",
       "39798          PARK ON PRIVATE PROPERTY               30 2024-03-06 09:59:00   \n",
       "46252          PARK ON PRIVATE PROPERTY               30 2024-03-06 03:42:00   \n",
       "52533    PARK-SIGNED HWY-EXC PERMT TIME               40 2024-03-06 23:29:00   \n",
       "52598          PARK ON PRIVATE PROPERTY               30 2024-03-06 09:46:00   \n",
       "...                                 ...              ...                 ...   \n",
       "1681044        PARK ON PRIVATE PROPERTY               30 2024-03-06 00:05:00   \n",
       "1707684            PARK IN A FIRE ROUTE              250 2024-03-06 14:23:00   \n",
       "1765660        PARK ON PRIVATE PROPERTY               30 2024-03-06 01:57:00   \n",
       "1780322    STAND VEH.-PROHIBIT TIME/DAY              100 2024-03-06 18:43:00   \n",
       "1791573        PARK ON PRIVATE PROPERTY               30 2024-03-06 07:45:00   \n",
       "\n",
       "          location1 location2 location3 location4 province  \\\n",
       "13667            AT       NaN       NaN       NaN       ON   \n",
       "39798            AT       NaN       NaN       NaN       ON   \n",
       "46252            AT       NaN       NaN       NaN       ON   \n",
       "52533            AT       NaN       NaN       NaN       ON   \n",
       "52598            AT       NaN       NaN       NaN       ON   \n",
       "...             ...       ...       ...       ...      ...   \n",
       "1681044          AT       NaN       NaN       NaN       ON   \n",
       "1707684  FIRE ROUTE       NaN       NaN       NaN       ON   \n",
       "1765660          AT       NaN       NaN       NaN       ON   \n",
       "1780322          AT       NaN       NaN       NaN       ON   \n",
       "1791573          AT       NaN       NaN       NaN       ON   \n",
       "\n",
       "        datetime_of_infraction  \n",
       "13667      2016-08-28 05:56:00  \n",
       "39798      2016-09-01 09:59:00  \n",
       "46252      2016-09-02 03:42:00  \n",
       "52533      2016-09-02 23:29:00  \n",
       "52598      2024-03-06 09:46:00  \n",
       "...                        ...  \n",
       "1681044    2022-11-14 00:05:00  \n",
       "1707684    2024-03-06 14:23:00  \n",
       "1765660    2022-12-01 01:57:00  \n",
       "1780322    2022-12-03 18:43:00  \n",
       "1791573    2022-12-06 07:45:00  \n",
       "\n",
       "[1349 rows x 12 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['location2'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1ff0f87d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010093925888435706"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['location2'].isna()].shape[0]/df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f87e6d",
   "metadata": {},
   "source": [
    "Very low percentage of rows with no address, so we can remove these rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a339ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.dropna(subset=[\"location2\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "878adc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged['location2'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2da482b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_number_masked</th>\n",
       "      <th>date_of_infraction</th>\n",
       "      <th>infraction_code</th>\n",
       "      <th>infraction_description</th>\n",
       "      <th>set_fine_amount</th>\n",
       "      <th>time_of_infraction</th>\n",
       "      <th>location1</th>\n",
       "      <th>location2</th>\n",
       "      <th>location3</th>\n",
       "      <th>location4</th>\n",
       "      <th>province</th>\n",
       "      <th>datetime_of_infraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86537</th>\n",
       "      <td>***29143</td>\n",
       "      <td>2016-09-09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PARK - LONGER THAN 3 HOURS</td>\n",
       "      <td>15</td>\n",
       "      <td>2024-03-06 03:54:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>0 NORTH WOODROW BLVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-09 03:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100494</th>\n",
       "      <td>***67342</td>\n",
       "      <td>2016-09-11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>STOP-SIGNED HWY-PROHIBIT TM/DY</td>\n",
       "      <td>60</td>\n",
       "      <td>2024-03-06 12:25:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>03 REAN DR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-11 12:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112190</th>\n",
       "      <td>***30983</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>STAND VEH.-PROHIBIT TIME/DAY</td>\n",
       "      <td>60</td>\n",
       "      <td>2024-03-06 10:30:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>0 PRINCE ARTHUR AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-13 10:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113109</th>\n",
       "      <td>***05604</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>PARK-SIGNED HWY-PROHIBIT DY/TM</td>\n",
       "      <td>50</td>\n",
       "      <td>2024-03-06 12:07:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>05 MARCELLINE CRES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-13 12:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113462</th>\n",
       "      <td>***05614</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>PARK-SIGNED HWY-PROHIBIT DY/TM</td>\n",
       "      <td>50</td>\n",
       "      <td>2024-03-06 12:41:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>03 REAN DR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2016-09-13 12:41:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257917</th>\n",
       "      <td>***25318</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 15:34:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>00. HURON ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-09-09 15:34:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307188</th>\n",
       "      <td>***09020</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 02:05:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0 MEADOWGLEN PL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-09-19 02:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427389</th>\n",
       "      <td>***75548</td>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>PARK-SIGNED HWY-PROHIBIT DY/TM</td>\n",
       "      <td>50</td>\n",
       "      <td>2024-03-06 14:07:00</td>\n",
       "      <td>N/S</td>\n",
       "      <td>0 THOMPSON ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-10-11 14:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502972</th>\n",
       "      <td>***84145</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 20:15:00</td>\n",
       "      <td>AT</td>\n",
       "      <td>0 DRIFTWOOD AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-12-12 20:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667205</th>\n",
       "      <td>***03980</td>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PARK ON PRIVATE PROPERTY</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-03-06 00:58:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0 FALSTAFF AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ON</td>\n",
       "      <td>2022-11-11 00:58:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag_number_masked date_of_infraction  infraction_code  \\\n",
       "86537            ***29143         2016-09-09              2.0   \n",
       "100494           ***67342         2016-09-11              9.0   \n",
       "112190           ***30983         2016-09-13              8.0   \n",
       "113109           ***05604         2016-09-13              5.0   \n",
       "113462           ***05614         2016-09-13              5.0   \n",
       "...                   ...                ...              ...   \n",
       "1257917          ***25318         2022-09-09              3.0   \n",
       "1307188          ***09020         2022-09-19              3.0   \n",
       "1427389          ***75548         2022-10-11              5.0   \n",
       "1502972          ***84145         2022-12-12              3.0   \n",
       "1667205          ***03980         2022-11-11              3.0   \n",
       "\n",
       "                 infraction_description  set_fine_amount  time_of_infraction  \\\n",
       "86537       PARK - LONGER THAN 3 HOURS                15 2024-03-06 03:54:00   \n",
       "100494   STOP-SIGNED HWY-PROHIBIT TM/DY               60 2024-03-06 12:25:00   \n",
       "112190     STAND VEH.-PROHIBIT TIME/DAY               60 2024-03-06 10:30:00   \n",
       "113109   PARK-SIGNED HWY-PROHIBIT DY/TM               50 2024-03-06 12:07:00   \n",
       "113462   PARK-SIGNED HWY-PROHIBIT DY/TM               50 2024-03-06 12:41:00   \n",
       "...                                 ...              ...                 ...   \n",
       "1257917        PARK ON PRIVATE PROPERTY               30 2024-03-06 15:34:00   \n",
       "1307188        PARK ON PRIVATE PROPERTY               30 2024-03-06 02:05:00   \n",
       "1427389  PARK-SIGNED HWY-PROHIBIT DY/TM               50 2024-03-06 14:07:00   \n",
       "1502972        PARK ON PRIVATE PROPERTY               30 2024-03-06 20:15:00   \n",
       "1667205        PARK ON PRIVATE PROPERTY               30 2024-03-06 00:58:00   \n",
       "\n",
       "        location1             location2 location3 location4 province  \\\n",
       "86537         N/S  0 NORTH WOODROW BLVD       NaN       NaN       ON   \n",
       "100494        N/S            03 REAN DR       NaN       NaN       ON   \n",
       "112190        N/S   0 PRINCE ARTHUR AVE       NaN       NaN       ON   \n",
       "113109        N/S    05 MARCELLINE CRES       NaN       NaN       ON   \n",
       "113462        N/S            03 REAN DR       NaN       NaN       ON   \n",
       "...           ...                   ...       ...       ...      ...   \n",
       "1257917        AT          00. HURON ST       NaN       NaN       ON   \n",
       "1307188         3       0 MEADOWGLEN PL       NaN       NaN       ON   \n",
       "1427389       N/S         0 THOMPSON ST       NaN       NaN       ON   \n",
       "1502972        AT       0 DRIFTWOOD AVE       NaN       NaN       ON   \n",
       "1667205         2        0 FALSTAFF AVE       NaN       NaN       ON   \n",
       "\n",
       "        datetime_of_infraction  \n",
       "86537      2016-09-09 03:54:00  \n",
       "100494     2016-09-11 12:25:00  \n",
       "112190     2016-09-13 10:30:00  \n",
       "113109     2016-09-13 12:07:00  \n",
       "113462     2016-09-13 12:41:00  \n",
       "...                        ...  \n",
       "1257917    2022-09-09 15:34:00  \n",
       "1307188    2022-09-19 02:05:00  \n",
       "1427389    2022-10-11 14:07:00  \n",
       "1502972    2022-12-12 20:15:00  \n",
       "1667205    2022-11-11 00:58:00  \n",
       "\n",
       "[1220 rows x 12 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['location2'].str.contains(r'^[0].+$', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b1ff0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['location2'] = df_merged['location2'].str.replace(r'^0+(.+)$', r'\\1', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "146f14b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_number_masked</th>\n",
       "      <th>date_of_infraction</th>\n",
       "      <th>infraction_code</th>\n",
       "      <th>infraction_description</th>\n",
       "      <th>set_fine_amount</th>\n",
       "      <th>time_of_infraction</th>\n",
       "      <th>location1</th>\n",
       "      <th>location2</th>\n",
       "      <th>location3</th>\n",
       "      <th>location4</th>\n",
       "      <th>province</th>\n",
       "      <th>datetime_of_infraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tag_number_masked, date_of_infraction, infraction_code, infraction_description, set_fine_amount, time_of_infraction, location1, location2, location3, location4, province, datetime_of_infraction]\n",
       "Index: []"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged[df_merged['location2'].str.contains(r'^[0].+$', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ab83184c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[242], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m num_in_location1 \u001b[38;5;241m=\u001b[39m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^[0-9]+$\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df_merged[num_in_location1]  \u001b[38;5;66;03m# Filter rows where 'location1' starts with a number\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_merged\u001b[38;5;241m.\u001b[39mloc[num_in_location1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcat(df_merged[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m), sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(filtered_df)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:885\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    884\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 885\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1888\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1887\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n\u001b[0;32m-> 1888\u001b[0m     indexer, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_mask_setitem_value(indexer, value)\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:789\u001b[0m, in \u001b[0;36m_LocationIndexer._maybe_mask_setitem_value\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    784\u001b[0m newkey \u001b[38;5;241m=\u001b[39m pi\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar_indexer(icols, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;66;03m# e.g. test_loc_setitem_boolean_mask_allfalse\u001b[39;00m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;66;03m# test_loc_setitem_ndframe_values_alignment\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\u001b[38;5;241m.\u001b[39m_align_series(indexer, value)\n\u001b[1;32m    790\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m (newkey, icols)\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(icols, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m icols\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(icols) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    796\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexing.py:2340\u001b[0m, in \u001b[0;36m_iLocIndexer._align_series\u001b[0;34m(self, indexer, ser, multiindex_indexer, using_cow)\u001b[0m\n\u001b[1;32m   2337\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m ser\n\u001b[1;32m   2338\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ser\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 2340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mreindex(new_ix)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   2342\u001b[0m \u001b[38;5;66;03m# 2 dims\u001b[39;00m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m single_aligner:\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;66;03m# reindex along index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:4981\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[0;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   4964\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m   4965\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m   4966\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4979\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4980\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m-> 4981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[1;32m   4982\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   4983\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   4984\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   4985\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   4986\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   4987\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m   4988\u001b[0m         tolerance\u001b[38;5;241m=\u001b[39mtolerance,\n\u001b[1;32m   4989\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:5521\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   5520\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_axes(\n\u001b[1;32m   5522\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[1;32m   5523\u001b[0m )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:5544\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5541\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   5543\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[0;32m-> 5544\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[1;32m   5545\u001b[0m     labels, level\u001b[38;5;241m=\u001b[39mlevel, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance, method\u001b[38;5;241m=\u001b[39mmethod\n\u001b[1;32m   5546\u001b[0m )\n\u001b[1;32m   5548\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[1;32m   5549\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   5550\u001b[0m     {axis: [new_index, indexer]},\n\u001b[1;32m   5551\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   5552\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   5553\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   5554\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:4434\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4431\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m   4433\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[0;32m-> 4434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4436\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "num_in_location1 = df_merged['location1'].str.contains(r'^[0-9]+$', regex=True)\n",
    "filtered_df = df_merged[num_in_location1]  # Filter rows where 'location1' starts with a number\n",
    "\n",
    "df_merged.loc[num_in_location1, 'location2'] = df_merged['location1'].astype(str).str.cat(df_merged['location2'].astype(str), sep=' ')\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9a4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
